# üê±üê∂ Classifica√ß√£o de Imagens: Cats vs Dogs (com TensorFlow Datasets)
# ===============================================================
# Este notebook foi adaptado para rodar no **VS Code + Windows 11 + Python 3.13.17**
# Usaremos o **TensorFlow Datasets (TFDS)** para baixar automaticamente o dataset Cats vs Dogs.
# Cada c√©lula possui explica√ß√µes did√°ticas em Markdown e coment√°rios no c√≥digo.

# ## üîπ 1. Prepara√ß√£o do Ambiente
# Execute este comando no terminal Bash do VS Code para instalar as depend√™ncias:
#
# ```bash
# pip install tensorflow tensorflow-datasets matplotlib numpy
# ```

# ## üîπ 2. Importa√ß√£o das Bibliotecas
import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import numpy as np

print("‚úÖ Bibliotecas importadas com sucesso!")

# ## üîπ 3. Carregar Dataset (TFDS baixa automaticamente)
# - O dataset Cats vs Dogs √© baixado e armazenado localmente pelo TFDS.
# - Usamos `as_supervised=True` para retornar tuplas (imagem, r√≥tulo).

(ds_train, ds_test), ds_info = tfds.load(
    'cats_vs_dogs',
    split=['train[:80%]', 'train[80%:]'],
    as_supervised=True,
    with_info=True
)

print("‚úÖ Dataset carregado com sucesso!")
print(ds_info)

# ## üîπ 4. Pr√©-processamento das Imagens
# - Redimensionar imagens para 128x128
# - Normalizar pixels para valores entre 0 e 1
# - Criar lotes (batchs) para treino

IMG_SIZE = (128, 128)
BATCH_SIZE = 32

def preprocess(image, label):
    image = tf.image.resize(image, IMG_SIZE)
    image = image / 255.0  # Normaliza√ß√£o
    return image, label

ds_train = ds_train.map(preprocess).batch(BATCH_SIZE).shuffle(1000)
ds_test = ds_test.map(preprocess).batch(BATCH_SIZE)

print("‚úÖ Pr√©-processamento conclu√≠do!")

# ## üîπ 5. Visualizar Amostras do Dataset
# Vamos exibir algumas imagens para verificar se o dataset foi carregado corretamente.

for images, labels in ds_train.take(1):
    plt.figure(figsize=(10,10))
    for i in range(9):
        plt.subplot(3,3,i+1)
        plt.imshow(images[i].numpy())
        plt.title("Cat" if labels[i].numpy()==0 else "Dog")
        plt.axis("off")
    plt.show()

# ## üîπ 6. Defini√ß√£o do Modelo CNN
# A rede neural convolucional ser√° composta por:
# - Camadas Conv2D + MaxPooling para extrair caracter√≠sticas visuais
# - Flatten para achatar a matriz em vetor
# - Dense para classifica√ß√£o bin√°ria (gato ou cachorro)

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(*IMG_SIZE, 3)),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid') # Bin√°ria: gato ou cachorro
])

model.summary()

# ## üîπ 7. Compila√ß√£o e Treinamento do Modelo
# - Otimizador: Adam (eficiente para CNNs)
# - Fun√ß√£o de perda: Binary Crossentropy (classifica√ß√£o bin√°ria)
# - M√©trica: Acur√°cia

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

history = model.fit(
    ds_train,
    validation_data=ds_test,
    epochs=5
)

# ## üîπ 8. Avalia√ß√£o do Modelo
# Vamos analisar as curvas de acur√°cia e loss para entender o desempenho.

plt.figure(figsize=(12,5))

# Acur√°cia
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Treino')
plt.plot(history.history['val_accuracy'], label='Valida√ß√£o')
plt.title('Acur√°cia')
plt.legend()

# Loss
plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Treino')
plt.plot(history.history['val_loss'], label='Valida√ß√£o')
plt.title('Loss')
plt.legend()

plt.show()

print("‚úÖ Treinamento e avalia√ß√£o conclu√≠dos!")
