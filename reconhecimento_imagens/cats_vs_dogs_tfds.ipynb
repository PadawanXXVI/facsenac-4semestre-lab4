{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🐶🐱 Classificação de Imagens: Gatos vs. Cachorros\n",
    "\n",
    "Este notebook demonstra **como treinar um modelo simples de deep learning** para classificar imagens de **gatos e cachorros** usando TensorFlow e TensorFlow Datasets.\n",
    "\n",
    "Compatível com **VS Code + Windows**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: tensorflow-datasets in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (4.9.9)\n",
      "Requirement already satisfied: matplotlib in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (6.32.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (2.3.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: dm-tree in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow-datasets) (0.1.9)\n",
      "Requirement already satisfied: etils>=1.9.1 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (1.13.0)\n",
      "Requirement already satisfied: immutabledict in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow-datasets) (4.2.1)\n",
      "Requirement already satisfied: promise in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: psutil in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow-datasets) (7.0.0)\n",
      "Requirement already satisfied: pyarrow in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow-datasets) (21.0.0)\n",
      "Requirement already satisfied: simple_parsing in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow-datasets) (0.1.7)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow-datasets) (1.17.2)\n",
      "Requirement already satisfied: toml in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow-datasets) (4.67.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: einops in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (0.8.1)\n",
      "Requirement already satisfied: fsspec in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2025.9.0)\n",
      "Requirement already satisfied: importlib_resources in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (6.5.2)\n",
      "Requirement already satisfied: zipp in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (3.23.0)\n",
      "Requirement already satisfied: rich in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: attrs>=18.2.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from dm-tree->tensorflow-datasets) (25.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from simple_parsing->tensorflow-datasets) (0.17.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tensorflow-metadata->tensorflow-datasets) (1.70.0)\n",
      "Requirement already satisfied: colorama in c:\\quartosemestre\\laboratorio-iv\\reconhecimento_imagens\\.venv\\lib\\site-packages (from tqdm->tensorflow-datasets) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# Instalar dependências (execute apenas uma vez no ambiente)\n",
    "!pip install tensorflow tensorflow-datasets matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar bibliotecas principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregar o dataset `cats_vs_dogs`\n",
    "\n",
    "O dataset vem inteiro como `train`. Precisamos **dividir manualmente em treino e teste**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Variant folder C:\\Users\\ander\\tensorflow_datasets\\cats_vs_dogs\\4.0.1 has no dataset_info.json\n",
      "c:\\QuartoSemestre\\laboratorio-IV\\reconhecimento_imagens\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\ander\\tensorflow_datasets\\cats_vs_dogs\\4.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Size...: 100%|██████████| 824887076/824887076 [00:00<00:00, 26568479933.77 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 26.50 url/s]\n",
      "                                                                \r"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"There is no item named 'PetImages\\\\\\\\Cat\\\\\\\\0.jpg' in the archive\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m (dataset, ds_info) = \u001b[43mtfds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcats_vs_dogs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_supervised\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_info\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m num_examples = ds_info.splits[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m].num_examples\n\u001b[32m      9\u001b[39m train_size = \u001b[38;5;28mint\u001b[39m(\u001b[32m0.8\u001b[39m * num_examples)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\QuartoSemestre\\laboratorio-IV\\reconhecimento_imagens\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:176\u001b[39m, in \u001b[36m_FunctionDecorator.__call__\u001b[39m\u001b[34m(self, function, instance, args, kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m metadata = \u001b[38;5;28mself\u001b[39m._start_call()\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    178\u001b[39m   metadata.mark_error()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\QuartoSemestre\\laboratorio-IV\\reconhecimento_imagens\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\load.py:666\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs, file_format)\u001b[39m\n\u001b[32m    541\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Loads the named dataset into a `tf.data.Dataset`.\u001b[39;00m\n\u001b[32m    542\u001b[39m \n\u001b[32m    543\u001b[39m \u001b[33;03m`tfds.load` is a convenience method that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    658\u001b[39m \u001b[33;03m    Split-specific information is available in `ds_info.splits`.\u001b[39;00m\n\u001b[32m    659\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# fmt: skip\u001b[39;00m\n\u001b[32m    660\u001b[39m dbuilder = _fetch_builder(\n\u001b[32m    661\u001b[39m     name=name,\n\u001b[32m    662\u001b[39m     data_dir=data_dir,\n\u001b[32m    663\u001b[39m     builder_kwargs=builder_kwargs,\n\u001b[32m    664\u001b[39m     try_gcs=try_gcs,\n\u001b[32m    665\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m \u001b[43m_download_and_prepare_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdbuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m as_dataset_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    669\u001b[39m   as_dataset_kwargs = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\QuartoSemestre\\laboratorio-IV\\reconhecimento_imagens\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\load.py:518\u001b[39m, in \u001b[36m_download_and_prepare_builder\u001b[39m\u001b[34m(dbuilder, download, download_and_prepare_kwargs)\u001b[39m\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[32m    517\u001b[39m   download_and_prepare_kwargs = download_and_prepare_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m   \u001b[43mdbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\QuartoSemestre\\laboratorio-IV\\reconhecimento_imagens\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:176\u001b[39m, in \u001b[36m_FunctionDecorator.__call__\u001b[39m\u001b[34m(self, function, instance, args, kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m metadata = \u001b[38;5;28mself\u001b[39m._start_call()\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    178\u001b[39m   metadata.mark_error()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\QuartoSemestre\\laboratorio-IV\\reconhecimento_imagens\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:763\u001b[39m, in \u001b[36mDatasetBuilder.download_and_prepare\u001b[39m\u001b[34m(self, download_dir, download_config, file_format, permissions)\u001b[39m\n\u001b[32m    761\u001b[39m   \u001b[38;5;28mself\u001b[39m.info.read_from_directory(\u001b[38;5;28mself\u001b[39m.data_dir)\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    764\u001b[39m \u001b[43m      \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    765\u001b[39m \u001b[43m      \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    768\u001b[39m   \u001b[38;5;66;03m# NOTE: If modifying the lines below to put additional information in\u001b[39;00m\n\u001b[32m    769\u001b[39m   \u001b[38;5;66;03m# DatasetInfo, you'll likely also want to update\u001b[39;00m\n\u001b[32m    770\u001b[39m   \u001b[38;5;66;03m# DatasetInfo.read_from_directory to possibly restore these attributes\u001b[39;00m\n\u001b[32m    771\u001b[39m   \u001b[38;5;66;03m# when reading from package data.\u001b[39;00m\n\u001b[32m    772\u001b[39m   \u001b[38;5;28mself\u001b[39m.info.download_size = dl_manager.downloaded_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\QuartoSemestre\\laboratorio-IV\\reconhecimento_imagens\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1808\u001b[39m, in \u001b[36mGeneratorBasedBuilder._download_and_prepare\u001b[39m\u001b[34m(self, dl_manager, download_config)\u001b[39m\n\u001b[32m   1805\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m download_config.max_examples_per_split == \u001b[32m0\u001b[39m:\n\u001b[32m   1806\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1808\u001b[39m split_infos = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_splits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1810\u001b[39m \u001b[38;5;66;03m# Update the info object with the splits.\u001b[39;00m\n\u001b[32m   1811\u001b[39m split_dict = splits_lib.SplitDict(split_infos)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\QuartoSemestre\\laboratorio-IV\\reconhecimento_imagens\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1782\u001b[39m, in \u001b[36mGeneratorBasedBuilder._generate_splits\u001b[39m\u001b[34m(self, dl_manager, download_config)\u001b[39m\n\u001b[32m   1775\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m split_name, generator \u001b[38;5;129;01min\u001b[39;00m utils.tqdm(\n\u001b[32m   1776\u001b[39m       split_generators.items(),\n\u001b[32m   1777\u001b[39m       desc=\u001b[33m\"\u001b[39m\u001b[33mGenerating splits...\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1778\u001b[39m       unit=\u001b[33m\"\u001b[39m\u001b[33m splits\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1779\u001b[39m       leave=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1780\u001b[39m   ):\n\u001b[32m   1781\u001b[39m     filename_template = \u001b[38;5;28mself\u001b[39m._get_filename_template(split_name=split_name)\n\u001b[32m-> \u001b[39m\u001b[32m1782\u001b[39m     future = \u001b[43msplit_builder\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit_split_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1784\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1785\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename_template\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1786\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisable_shuffling\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdisable_shuffling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1787\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnondeterministic_order\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnondeterministic_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1788\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m     split_info_futures.append(future)\n\u001b[32m   1791\u001b[39m \u001b[38;5;66;03m# Process the result of the beam pipeline.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\QuartoSemestre\\laboratorio-IV\\reconhecimento_imagens\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\split_builder.py:447\u001b[39m, in \u001b[36mSplitBuilder.submit_split_generation\u001b[39m\u001b[34m(self, split_name, generator, filename_template, disable_shuffling, nondeterministic_order)\u001b[39m\n\u001b[32m    442\u001b[39m     logging.warning(\n\u001b[32m    443\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m`nondeterministic_order` is set to True for a dataset that does\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    444\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m not use beam. Setting `disable_shuffling` to True.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    445\u001b[39m     )\n\u001b[32m    446\u001b[39m     build_kwargs[\u001b[33m'\u001b[39m\u001b[33mdisable_shuffling\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_from_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbuild_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Otherwise, beam required\u001b[39;00m\n\u001b[32m    449\u001b[39m   unknown_generator_type = \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    450\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mInvalid split generator value for split `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    451\u001b[39m       \u001b[33m'\u001b[39m\u001b[33mExpected generator or apache_beam object. Got: \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    452\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(generator)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    453\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\QuartoSemestre\\laboratorio-IV\\reconhecimento_imagens\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\split_builder.py:508\u001b[39m, in \u001b[36mSplitBuilder._build_from_generator\u001b[39m\u001b[34m(self, split_name, generator, filename_template, disable_shuffling)\u001b[39m\n\u001b[32m    498\u001b[39m serialized_info = \u001b[38;5;28mself\u001b[39m._features.get_serialized_info()\n\u001b[32m    499\u001b[39m writer = writer_lib.Writer(\n\u001b[32m    500\u001b[39m     serializer=example_serializer.ExampleSerializer(serialized_info),\n\u001b[32m    501\u001b[39m     filename_template=filename_template,\n\u001b[32m   (...)\u001b[39m\u001b[32m    506\u001b[39m     ignore_duplicates=\u001b[38;5;28mself\u001b[39m._ignore_duplicates,\n\u001b[32m    507\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m    \u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGenerating \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msplit_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m examples...\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43munit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m examples\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_num_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmininterval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_features\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\QuartoSemestre\\laboratorio-IV\\reconhecimento_imagens\\.venv\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\QuartoSemestre\\laboratorio-IV\\reconhecimento_imagens\\.venv\\Lib\\site-packages\\tensorflow_datasets\\image_classification\\cats_vs_dogs.py:119\u001b[39m, in \u001b[36mCatsVsDogs._generate_examples\u001b[39m\u001b[34m(self, archive)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m zipfile.ZipFile(buffer, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m new_zip:\n\u001b[32m    118\u001b[39m   new_zip.writestr(norm_fname, img_recoded.numpy())\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m new_fobj = \u001b[43mzipfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm_fname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m record = {\n\u001b[32m    122\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m: new_fobj,\n\u001b[32m    123\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimage/filename\u001b[39m\u001b[33m\"\u001b[39m: norm_fname,\n\u001b[32m    124\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m: label,\n\u001b[32m    125\u001b[39m }\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m norm_fname, record\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\zipfile\\__init__.py:1639\u001b[39m, in \u001b[36mZipFile.open\u001b[39m\u001b[34m(self, name, mode, pwd, force_zip64)\u001b[39m\n\u001b[32m   1636\u001b[39m     zinfo.compress_level = \u001b[38;5;28mself\u001b[39m.compresslevel\n\u001b[32m   1637\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1638\u001b[39m     \u001b[38;5;66;03m# Get info object for name\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1639\u001b[39m     zinfo = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgetinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1641\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m   1642\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\zipfile\\__init__.py:1567\u001b[39m, in \u001b[36mZipFile.getinfo\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1565\u001b[39m info = \u001b[38;5;28mself\u001b[39m.NameToInfo.get(name)\n\u001b[32m   1566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1567\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m   1568\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mThere is no item named \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m in the archive\u001b[39m\u001b[33m'\u001b[39m % name)\n\u001b[32m   1570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m info\n",
      "\u001b[31mKeyError\u001b[39m: \"There is no item named 'PetImages\\\\\\\\Cat\\\\\\\\0.jpg' in the archive\""
     ]
    }
   ],
   "source": [
    "(dataset, ds_info) = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split='train',\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "num_examples = ds_info.splits['train'].num_examples\n",
    "train_size = int(0.8 * num_examples)\n",
    "\n",
    "ds_train = dataset.take(train_size)\n",
    "ds_test = dataset.skip(train_size)\n",
    "\n",
    "print(f\"Total de imagens: {num_examples}\")\n",
    "print(f\"Treino: {train_size}, Teste: {num_examples - train_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizar algumas imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label) in enumerate(dataset.take(9)):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Cachorro\" if label.numpy() == 1 else \"Gato\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pré-processamento das imagens\n",
    "- Redimensionar para 128x128\n",
    "- Normalizar valores de pixel para `[0,1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "ds_train = ds_train.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Criar o modelo de rede neural convolucional (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(ds_train, validation_data=ds_test, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Avaliar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(ds_test)\n",
    "print(f\"Acurácia no teste: {acc*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
